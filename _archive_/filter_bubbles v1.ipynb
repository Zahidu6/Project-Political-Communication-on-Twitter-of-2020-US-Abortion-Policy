{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a9b1e5",
   "metadata": {},
   "source": [
    "# filter bubble effect (working title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362098f7",
   "metadata": {},
   "source": [
    "### #pre import needed packages\n",
    "\n",
    "* data/us_senetors_040722.csv\n",
    "* data/us_representatives_040722.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a93a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "#!pip install vaderSentiment\n",
    "#!pip install twarc\n",
    "\n",
    "from datetime import date, datetime, timezone\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 400\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime, timezone, timedelta\n",
    "import csv\n",
    "\n",
    "from twarc import Twarc2 #twitter\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer #sentiment vader\n",
    "sentimentAnalyser = SentimentIntensityAnalyzer() #sentiment vader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c67b3",
   "metadata": {},
   "source": [
    "### #1 import of members of congress (senators, representatives) and keywords on 'abortion'\n",
    "\n",
    "* data/us_senators_040722.csv\n",
    "* data/us_representatives_040722.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc9bca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senators:  100\n",
      "Representatives:  436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/_dtmnfpx1552ksv4hpb8ly3h0000gn/T/ipykernel_4408/1323361081.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  senators['twitter'] = senators['Link'].str.replace('https://twitter.com/','')\n",
      "/var/folders/qh/_dtmnfpx1552ksv4hpb8ly3h0000gn/T/ipykernel_4408/1323361081.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  representatives['twitter'] = representatives['Link'].str.replace('https://twitter.com/','')\n"
     ]
    }
   ],
   "source": [
    "#file imports (all tweets from filename.csv)\n",
    "senators = []\n",
    "representatives = []\n",
    "keywords=[]\n",
    "\n",
    "#read\n",
    "senators=pd.read_csv('data/us_senators_040722.csv', header='infer', sep=\";\", dtype=str)\n",
    "representatives=pd.read_csv('data/us_representatives_040722.csv', header='infer', sep=\";\", dtype=str)\n",
    "\n",
    "#add twitter handle (extraction from link)\n",
    "senators['twitter'] = senators['Link'].str.replace('https://twitter.com/','')\n",
    "representatives['twitter'] = representatives['Link'].str.replace('https://twitter.com/','')\n",
    "\n",
    "#keyword to list\n",
    "with open('data/keywords.csv', 'r') as read_keywords:\n",
    "    next(read_keywords)\n",
    "    lines = read_keywords.readlines()\n",
    "    for line in lines:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            keywords.append(line)\n",
    "\n",
    "#prints---------\n",
    "print(\"Senators: \", len(senators))\n",
    "print(\"Representatives: \",len(representatives))\n",
    "print()\n",
    "#print(keywords)\n",
    "#display(senators.head(5))\n",
    "#display(representatives.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d32eac",
   "metadata": {},
   "source": [
    "### #2 lets focus on senators and process a twitter query\n",
    "\n",
    "* https://github.com/twitterdev/getting-started-with-the-twitter-api-v2-for-academic-research/blob/main/modules/5-how-to-write-search-queries.md\n",
    "\n",
    "#### it should include:\n",
    "\n",
    "* (a)  English as language (\"lang:en\")\n",
    "* (b)  members of congress (\"from:HANDLE OR from:HANDLE OR ...\")\n",
    "* (c)  keywords for abortion (list provided by Jana)\n",
    "\n",
    "\n",
    "!queries for senators are devided in 6 queries due to character size of query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643ccfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "\n",
    "#todo - what query do we want?\n",
    "\n",
    "#a\n",
    "#query=str(\"lang:en \")\n",
    "\n",
    "#b\n",
    "#for index, row in senators.iterrows():\n",
    "#    query=query+str(\"from:\")+str(row['twitter'])+str(\" OR \")\n",
    "#c\n",
    "#for entry in keywords:\n",
    "#    query=query+str(entry)+str(\" OR \")\n",
    "\n",
    "#prints---------\n",
    "#print(\"'query' done!\")\n",
    "#print()\n",
    "#print(\"query=\",query, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0648e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query split\n",
    "\n",
    "#query language and keywords (323 characters)\n",
    "query1=str(\"lang:en (abortion OR pregnancies OR pregnancy OR pregnant OR unborn OR embryonic OR pro choice OR pro life OR prochoice OR prolife OR roevwade OR roe v wade OR right to life OR righttolife OR infanticide OR parenthood OR abortions OR embryo OR contraception OR ultrasound OR planned parenthood OR reproductive OR ultrasounds)\")\n",
    "\n",
    "#senators\n",
    "query2a=str(\" AND (from:SenatorBaldwin OR from:SenJohnBarrasso OR from:SenatorBennet OR from:MarshaBlackburn OR from:SenBlumenthal OR from:RoyBlunt OR from:CoryBooker OR from:JohnBoozman OR from:SenatorBraun OR from:SenSherrodBrown OR from:SenatorBurr OR from:SenatorCantwell OR from:SenCapito OR from:SenatorCardin OR from:SenatorCarper OR from:SenBobCasey OR from:SenBillCassidy OR from:SenatorCollins)\") \n",
    "\n",
    "query2b=str(\" AND (from:ChrisCoons OR from:JohnCornyn OR from:SenCortezMasto OR from:SenTomCotton OR from:SenKevinCramer OR from:MikeCrapo OR from:SenTedCruz OR from:SteveDaines OR from:SenDuckworth OR from:SenatorDurbin OR from:SenJoniErnst OR from:SenFeinstein OR from:SenatorFischer OR from:SenGillibrand OR from:LindseyGrahamSC OR from:ChuckGrassley OR from:SenatorHagerty OR from:SenatorHassan)\")  \n",
    "\n",
    "query2c=str(\" AND (from:HawleyMO OR from:MartinHeinrich OR from:SenatorHick OR from:maziehirono OR from:SenJohnHoeven OR from:SenHydeSmith OR from:JimInhofe OR from:SenRonJohnson OR from:timkaine OR from:SenMarkKelly OR from:SenJohnKennedy OR from:SenAngusKing OR from:SenAmyKlobuchar OR from:SenatorLankford OR from:SenatorLeahy OR from:SenMikeLee OR from:SenatorLujan OR from:SenLummis OR from:Sen_JoeManchin OR from:SenMarkey OR from:SenatorMarshall)\") \n",
    "\n",
    "query2d=str(\" AND (from:senatemajldr OR from:SenatorMenendez OR from:SenJeffMerkley OR from:JerryMoran OR from:lisamurkowski OR from:ChrisMurphyCT OR from:PattyMurray OR from:ossoff OR from:SenAlexPadilla OR from:RandPaul OR from:SenGaryPeters OR from:senrobportman OR from:SenJackReed OR from:SenatorRisch OR from:SenatorRomney OR from:SenJackyRosen OR from:SenatorRounds OR from:marcorubio OR from:SenSanders)\")\n",
    "\n",
    "query2e=str(\" AND (from:SenSasse OR from:SenBrianSchatz OR from:SenSchumer OR from:SenRickScott OR from:SenatorTimScott OR from:SenatorShaheen OR from:SenShelby OR from:SenatorSinema OR from:SenTinaSmith OR from:SenStabenow OR from:SenDanSullivan OR from:SenatorTester OR from:SenJohnThune OR from:SenThomTillis OR from:SenToomey OR from:SenTuberville OR from:ChrisVanHollen OR from:MarkWarner OR from:SenatorWarnock OR from:SenWarren OR from:SenWhitehouse OR from:SenatorWicker OR from:RonWyden OR from:SenToddYoung)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b521e",
   "metadata": {},
   "source": [
    "### #3 lets focus on the senators-df only and download the tweets\n",
    "\n",
    "* define timespan (start, end) for download\n",
    "* download tweets using the computed query to dataframe 'tweets'\n",
    "* converting columns\n",
    "    * 'author_id','id','conversation_id' to string\n",
    "    * 'created_at' to date and setting it as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758701fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TIMESPAN:\n",
    "#Today(last midnight) minus 6 days\n",
    "today=datetime.now()\n",
    "timespan_days=6\n",
    "timespan = today - timedelta(days=timespan_days) #minus 6 days\n",
    "#calculated\n",
    "start = datetime(timespan.year, timespan.month, timespan.day, 0, 0, 0, 0, tzinfo=timezone.utc)\n",
    "end = datetime(today.year, today.month, today.day, 0, 0, 0, 0, tzinfo=timezone.utc)\n",
    "\n",
    "#manual set of start- and start- and enddates for twitter-elevated access\n",
    "start = datetime(2022, 7, 9, 0, 0, 0, 0, tzinfo=timezone.utc) #we should see a peak\n",
    "end = datetime(2022, 7, 23, 0, 0, 0, 0, tzinfo=timezone.utc) \n",
    "\n",
    "\n",
    "#TWITTER\n",
    "#bearer_token\n",
    "bearer_token_academic_summerschool = \"AAAAAAAAAAAAAAAAAAAAAHCpewEAAAAAp0ENemYtS4sb4uUoKufBXd4zoo0%3DOFrhxhAmsi15Gq7WHFUg3e0Dlcd9yyVBKmH7Zg98keVfupTjJm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2088fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rate limit exceeded: sleeping 85.33943700790405 secs\n",
      "Hit the 1 request/second rate limit, sleeping for 10 seconds. This shouldn't happen with normal usage of twarc, and may indicate multiple clients interacting with the Twitter API at the same time.\n",
      "rate limit exceeded: sleeping 117.91361999511719 secs\n",
      "Hit the 1 request/second rate limit, sleeping for 10 seconds. This shouldn't happen with normal usage of twarc, and may indicate multiple clients interacting with the Twitter API at the same time.\n",
      "Hit the 1 request/second rate limit, sleeping for 10 seconds. This shouldn't happen with normal usage of twarc, and may indicate multiple clients interacting with the Twitter API at the same time.\n"
     ]
    }
   ],
   "source": [
    "#QueryA\n",
    "queryA=query1+query2a\n",
    "query=query1\n",
    "\n",
    "bearer_token = bearer_token_academic_summerschool\n",
    "twarc_client = Twarc2(bearer_token=bearer_token)\n",
    "results = [] #df for \"new\" tweets\n",
    "for tweet in twarc_client.search_all(\n",
    "        query,\n",
    "        start_time=start,\n",
    "        end_time=end):\n",
    "    results.append(tweet)\n",
    "    \n",
    "tweets = []\n",
    "tweets = pd.json_normalize(results, record_path=['data']) #creating dataframe\n",
    "\n",
    "#column conversion (datatypes)\n",
    "tweets = tweets.astype({'author_id': 'str', 'id': 'str','conversation_id': 'str'})\n",
    "tweets['created_at']= pd.to_datetime(tweets['created_at'])\n",
    "#setting index to date\n",
    "tweets = tweets.set_index(\"created_at\")\n",
    "\n",
    "#prints\n",
    "#print (\"tweets_dates:\")\n",
    "#print(\"   min:\", tweets.index.min())\n",
    "#print(\"   max:\", tweets.index.max())\n",
    "print()\n",
    "print(\"Number of downloaded tweets: \", len(tweets))\n",
    "print()\n",
    "display(tweets.head(2))\n",
    "tweets2a=tweets\n",
    "print(\"No. of tweets in queryA: \", len(tweets2a))\n",
    "display(tweets2a.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef59124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QueryB\n",
    "queryB=query1+query2b\n",
    "query=queryB\n",
    "\n",
    "bearer_token = bearer_token_academic_summerschool\n",
    "twarc_client = Twarc2(bearer_token=bearer_token)\n",
    "results = [] #df for \"new\" tweets\n",
    "for tweet in twarc_client.search_all(\n",
    "        query,\n",
    "        start_time=start,\n",
    "        end_time=end):\n",
    "    results.append(tweet)\n",
    "    \n",
    "tweets = []\n",
    "tweets = pd.json_normalize(results, record_path=['data']) #creating dataframe\n",
    "\n",
    "#column conversion (datatypes)\n",
    "tweets = tweets.astype({'author_id': 'str', 'id': 'str','conversation_id': 'str'})\n",
    "tweets['created_at']= pd.to_datetime(tweets['created_at'])\n",
    "#setting index to date\n",
    "tweets = tweets.set_index(\"created_at\")\n",
    "\n",
    "#prints\n",
    "#print (\"tweets_dates:\")\n",
    "#print(\"   min:\", tweets.index.min())\n",
    "#print(\"   max:\", tweets.index.max())\n",
    "#print()\n",
    "#print(\"Number of downloaded tweets: \", len(tweets))\n",
    "#print()\n",
    "#display(tweets.head(2))\n",
    "tweets2b=tweets\n",
    "print(\"No. of tweets in queryB: \", len(tweets2b))\n",
    "display(tweets2b.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab39c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QueryC\n",
    "queryC=query1+query2c\n",
    "query=queryC\n",
    "\n",
    "bearer_token = bearer_token_academic_summerschool\n",
    "twarc_client = Twarc2(bearer_token=bearer_token)\n",
    "results = [] #df for \"new\" tweets\n",
    "for tweet in twarc_client.search_all(\n",
    "        query,\n",
    "        start_time=start,\n",
    "        end_time=end):\n",
    "    results.append(tweet)\n",
    "    \n",
    "tweets = []\n",
    "tweets = pd.json_normalize(results, record_path=['data']) #creating dataframe\n",
    "\n",
    "#column conversion (datatypes)\n",
    "tweets = tweets.astype({'author_id': 'str', 'id': 'str','conversation_id': 'str'})\n",
    "tweets['created_at']= pd.to_datetime(tweets['created_at'])\n",
    "#setting index to date\n",
    "tweets = tweets.set_index(\"created_at\")\n",
    "\n",
    "#prints\n",
    "#print (\"tweets_dates:\")\n",
    "#print(\"   min:\", tweets.index.min())\n",
    "#print(\"   max:\", tweets.index.max())\n",
    "#print()\n",
    "#print(\"Number of downloaded tweets: \", len(tweets))\n",
    "#print()\n",
    "#display(tweets.head(2))\n",
    "tweets2c=tweets\n",
    "print(\"No. of tweets in queryC: \", len(tweets2c))\n",
    "display(tweets2c.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147925dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QueryD\n",
    "queryD=query1+query2d\n",
    "query=queryD\n",
    "\n",
    "bearer_token = bearer_token_academic_summerschool\n",
    "twarc_client = Twarc2(bearer_token=bearer_token)\n",
    "results = [] #df for \"new\" tweets\n",
    "for tweet in twarc_client.search_all(\n",
    "        query,\n",
    "        start_time=start,\n",
    "        end_time=end):\n",
    "    results.append(tweet)\n",
    "    \n",
    "tweets = []\n",
    "tweets = pd.json_normalize(results, record_path=['data']) #creating dataframe\n",
    "\n",
    "#column conversion (datatypes)\n",
    "tweets = tweets.astype({'author_id': 'str', 'id': 'str','conversation_id': 'str'})\n",
    "tweets['created_at']= pd.to_datetime(tweets['created_at'])\n",
    "#setting index to date\n",
    "tweets = tweets.set_index(\"created_at\")\n",
    "\n",
    "#prints\n",
    "#print (\"tweets_dates:\")\n",
    "#print(\"   min:\", tweets.index.min())\n",
    "#print(\"   max:\", tweets.index.max())\n",
    "#print()\n",
    "#print(\"Number of downloaded tweets: \", len(tweets))\n",
    "#print()\n",
    "#display(tweets.head(2))\n",
    "tweets2d=tweets\n",
    "print(\"No. of tweets in queryD: \", len(tweets2d))\n",
    "display(tweets2d.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e650de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QueryE\n",
    "queryE=query1+query2e\n",
    "query=queryE\n",
    "\n",
    "bearer_token = bearer_token_academic_summerschool\n",
    "twarc_client = Twarc2(bearer_token=bearer_token)\n",
    "results = [] #df for \"new\" tweets\n",
    "for tweet in twarc_client.search_all(\n",
    "        query,\n",
    "        start_time=start,\n",
    "        end_time=end):\n",
    "    results.append(tweet)\n",
    "    \n",
    "tweets = []\n",
    "tweets = pd.json_normalize(results, record_path=['data']) #creating dataframe\n",
    "\n",
    "#column conversion (datatypes)\n",
    "tweets = tweets.astype({'author_id': 'str', 'id': 'str','conversation_id': 'str'})\n",
    "tweets['created_at']= pd.to_datetime(tweets['created_at'])\n",
    "#setting index to date\n",
    "tweets = tweets.set_index(\"created_at\")\n",
    "\n",
    "#prints\n",
    "#print (\"tweets_dates:\")\n",
    "#print(\"   min:\", tweets.index.min())\n",
    "#print(\"   max:\", tweets.index.max())\n",
    "#print()\n",
    "#print(\"Number of downloaded tweets: \", len(tweets))\n",
    "#print()\n",
    "#display(tweets.head(2))\n",
    "tweets2e=tweets\n",
    "print(\"No. of tweets in queryE: \", len(tweets2e))\n",
    "display(tweets2e.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5075bf8",
   "metadata": {},
   "source": [
    "### #4 Putting Sentiment-Analysis over the tweets\n",
    "\n",
    "using Vader sentiment analysis\n",
    "\n",
    "* which can be seen in the columns '' and ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating vader-sentiment for whole phrase (column\"text\")\n",
    "def vader_sentiment_score(text):\n",
    "    scores = sentimentAnalyser.polarity_scores(text) # Run VADER on the text\n",
    "    compound_score = scores['compound'] # Extract the compound score, whole phase\n",
    "    return compound_score # Return compound score\n",
    "\n",
    "def vader_sentiment_phrase(vader_sentiment_score):\n",
    "    #scores = sentimentAnalyser.polarity_scores(text) # Run VADER on the text\n",
    "    #compound_score = scores['compound'] # Extract the compound score, whole phase\n",
    "    if vader_sentiment_score >= 0.05 :\n",
    "        compound_phrase=str(\"positive\")\n",
    "    elif vader_sentiment_score <= - 0.05 :\n",
    "        compound_phrase=str(\"negative\")\n",
    "    else :\n",
    "        compound_phrase=str(\"neutral\")\n",
    "    return compound_phrase # Return compound phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bb2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test, if the analysis works\n",
    "vader_sentiment_score('I like the Marvel movies') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d15efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating column \n",
    "tweets_sentiment=[]\n",
    "tweets_sentiment=tweets\n",
    "tweets_sentiment['vader_sentiment_score'] = tweets_sentiment['text'].apply(vader_sentiment_score)\n",
    "tweets_sentiment['vader_sentiment_phrase'] = tweets_sentiment['vader_sentiment_score'].apply(vader_sentiment_phrase)\n",
    "\n",
    "#prints---------\n",
    "print()\n",
    "print(\"Number of tweets with sentiments: \", len(tweets_sentiment))\n",
    "print()\n",
    "display(tweets_sentiment.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee60a2",
   "metadata": {},
   "source": [
    "### #5 Saving to File\n",
    "\n",
    "to 'data/downloaded_tweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=str(today.strftime(\"%Y\"))+str(\"-\")+str(today.strftime(\"%m\"))+str(\"-\")+str(today.strftime(\"%d\"))\n",
    "filename=str(\"data/downloaded_tweets\")+\"_\"+date+str(\"\")+str(\".csv\")\n",
    "tweets_sentiment.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462117d1",
   "metadata": {},
   "source": [
    "### #6 Visualization\n",
    "\n",
    "of sentiments over time only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd112a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting by date\n",
    "tweets_sentiment.sort_values(by=['created_at'], inplace=True, ascending=True)\n",
    "#display(tweets_sentiment)\n",
    "\n",
    "tweets_sentiment['vader_sentiment_score'].plot(\n",
    "    title=f\"query: '{query}' - Tweet's Vader Sentiment Score\");\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
